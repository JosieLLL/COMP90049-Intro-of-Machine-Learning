{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W_oI1y6-cY4d"
   },
   "source": [
    "# Assignment 1: K-Nearest Neighbors Classification (15 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "XIBjsAqjcY4e"
   },
   "source": [
    "Student Name: Jiayi Li\n",
    "\n",
    "Student ID: 1097419"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Huv7ALVcY4f"
   },
   "source": [
    "## General info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p07JVvoScY4g"
   },
   "source": [
    "<b>Due date</b>: Friday, 19 March 2021 5pm\n",
    "\n",
    "<b>Submission method</b>: Canvas submission\n",
    "\n",
    "<b>Submission materials</b>: completed copy of this iPython notebook\n",
    "\n",
    "<b>Late submissions</b>: -10% per day (both week and weekend days counted)\n",
    "\n",
    "<b>Marks</b>: 15% of mark for class. \n",
    "\n",
    "<b>Materials</b>: See [Using Jupyter Notebook and Python page](https://canvas.lms.unimelb.edu.au/courses/105477/pages/python-and-jupyter-notebooks?module_item_id=2613813) on Canvas (under Modules> Coding Resources) for information on the basic setup required for this class, including an iPython notebook viewer and the python packages NLTK, Numpy, Scipy, Matplotlib, Scikit-Learn, and Gensim. In particular, if you are not using a lab computer which already has it installed, we recommend installing all the data for NLTK, since you will need various parts of it to complete this assignment. Deep learning libraries such as keras and pytorch are also allowed.  You can also use any Python built-in packages, but do not use any other 3rd party packages (the packages listed above are all fine to use); if your iPython notebook doesn't run on the marker's machine, you will lose marks. <b> You should use Python 3</b>.  \n",
    "\n",
    "\n",
    "<b>Evaluation</b>: Your iPython notebook should run end-to-end without any errors in a reasonable amount of time, and you must follow all instructions provided below, including specific implementation requirements and instructions for what needs to be printed (please avoid printing output we don't ask for). You should edit the sections below where requested, but leave the rest of the code as is. You should leave the output from running your code in the iPython notebook you submit, to assist with marking. The amount each section is worth is given in parenthesis after the instructions. \n",
    "\n",
    "You will be marked not only on the correctness of your methods, but also the quality and efficency of your code: in particular, you should be careful to use Python built-in functions and operators when appropriate and pick descriptive variable names that adhere to <a href=\"https://www.python.org/dev/peps/pep-0008/\">Python style requirements</a>. If you think it might be unclear what you are doing, you should comment your code to help the marker make sense of it. We reserve the right to deduct up to 2 marks for unreadable or exessively inefficient code.\n",
    "\n",
    "<b>Updates</b>: Any major changes to the assignment will be announced via Canvas. Minor changes and clarifications will be announced on the discussion board (Piazza -> Assignment_1); we recommend you check it regularly.\n",
    "\n",
    "<b>Academic misconduct</b>: For most people, collaboration will form a natural part of the undertaking of this homework, and we encourge you to discuss it in general terms with other students. However, this ultimately is still an individual task, and so reuse of code or other instances of clear influence will be considered cheating. Please check the <a href=\"https://canvas.lms.unimelb.edu.au/courses/105477/modules\">CIS Academic Honesty training</a> for more information. We will be checking submissions for originality and will invoke the Universityâ€™s <a href=\"http://academichonesty.unimelb.edu.au/policy.html\">Academic Misconduct policy</a> where inappropriate levels of collusion or plagiarism are deemed to have taken place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wseHhYGScY4g"
   },
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wH9UvbJTcY4h"
   },
   "source": [
    "In this assignment, you will implement the K-nearest neighbor (KNN) classification algorithm and apply it to a real-world machine learning data set. In particular we will classify zoo animals into seven animal categories. \n",
    "\n",
    "Firstly, you will read in the dataset into a train and a test set (Q1). Secondly, you will implement different distance functions (Q2). Thirdly, you will implement a KNN classifier (Q3). You will apply and evaluate your classifier on the data set exploring different parameters (Q4, Q5). Finally, you will critically discuss your results (Q6)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Loading the data (2.0 marks)\n",
    "\n",
    "**Instructions:** For this assignment we will develop a K-Nearest Neighbors (KNN) classifier to classify animals in the zoo into pre-defined categories of animals, namely\n",
    "```\n",
    "1: mammal\n",
    "2: bird\n",
    "3: reptile\n",
    "4: fish\n",
    "5: amphibian\n",
    "6: insect\n",
    "7: invertebrate\n",
    "```\n",
    "\n",
    "We use a data set of zoo animals from the UCI Machine learning repository.\n",
    "\n",
    "The original data can be found here: https://archive.ics.uci.edu/ml/datasets/Zoo. \n",
    "\n",
    "The dataset consists of 101 instances. Each instance corresponds to an animal which has a unique identifier (the name of the animal; first field) and is characterized with 16 features:\n",
    "\n",
    "```\n",
    "   1. hair\t\t    Boolean\n",
    "   2. feathers\t\tBoolean\n",
    "   3. eggs\t\t    Boolean\n",
    "   4. milk\t\t    Boolean\n",
    "   5. airborne\t\tBoolean\n",
    "   6. aquatic\t\tBoolean\n",
    "   7. predator\t\tBoolean\n",
    "   8. toothed\t\tBoolean\n",
    "   9. backbone\t\tBoolean\n",
    "  10. breathes\t\tBoolean\n",
    "  11. venomous\t\tBoolean\n",
    "  12. fins\t\t    Boolean\n",
    "  13. legs\t\t    Numeric (set of values: {0,2,4,5,6,8})\n",
    "  14. tail\t\t    Boolean\n",
    "  15. domestic\t\tBoolean\n",
    "  16. catsize\t\tBoolean\n",
    "```\n",
    "\n",
    "You need to first obtain this dataset, which is on Canvas (assignment 1). The files we will be using are called *zoo.data* and *zoo.labels*. Make sure the files are saved in the same folder as this notebook.\n",
    "\n",
    "Both files are in comma-separated value format.\n",
    "\n",
    "*zoo.features* contains 101 instances, one line per instance. The first field is the unique instance identifier (name of animals). The following fields contain the 16 features, as described above.\n",
    "\n",
    "*zoo.labels* contains the gold labels (i.e., one of the seven classes above), for one instance per line. Again, the first field is the instance identifier, and the second field the instance label.\n",
    "\n",
    "**Task**: Read the two files  \n",
    "1. create a **training_feature** set (list of features for the first 90 instances in the zoo.* files) and a **training_label** set (list of labels for the corresponding). \n",
    "2. create a **test_feature** set (list of features of the remaining instances in the zoo.* files) and a **test_label** set (list of labels for the corresponding). \n",
    "\n",
    "**Check**: Use the assertion statements in *\"For your testing\"* to validate your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open(\"zoo.features\", 'r').readlines()\n",
    "gold = open(\"zoo.labels\", 'r').readlines()\n",
    "\n",
    "train_features = []\n",
    "train_labels   = []\n",
    "test_features = []\n",
    "test_labels   = []\n",
    "\n",
    "# iterate over each instance, turn string features into number features, store them as train/test_features\n",
    "for instance in data:\n",
    "    inst_format = instance.strip().split(',') \n",
    "    num_features = [] \n",
    "    \n",
    "    # refered from: https://www.kite.com/python/answers/how-to-extract-integers-from-a-string-in-python\n",
    "    for word in inst_format:\n",
    "        if word.isdigit():\n",
    "            num_features.append(int(word))\n",
    "            \n",
    "    if data.index(instance) < 90:\n",
    "        train_features.append(num_features)\n",
    "    else:\n",
    "        test_features.append(num_features)\n",
    "\n",
    "# interate over each label, format them, put them into train/test_labels\n",
    "for label in gold:\n",
    "    label_format = label.strip().split(',')\n",
    "    inst_label = label_format[1]\n",
    "    \n",
    "    if gold.index(label) < 90:\n",
    "        train_labels.append(int(inst_label))\n",
    "    else:\n",
    "        test_labels.append(int(inst_label))\n",
    "        \n",
    "\n",
    "# Reference for this question: The University of Melbourne,(2021) Week1_demo_1.ipynb (Version 1.0) [Source code]. https://canvas.lms.unimelb.edu.au/courses/105477/files/6873411?wrap=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 4, 0, 0, 1], [1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 4, 1, 0, 1], [0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0], [1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 4, 0, 0, 1], [1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 4, 1, 0, 1], [1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 4, 1, 0, 1], [1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 4, 1, 1, 1], [0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0], [0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0], [1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 4, 0, 1, 0], [1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 4, 1, 0, 1], [0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 2, 1, 1, 0], [0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0], [0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 4, 0, 0, 0], [0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 6, 0, 0, 0], [0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 2, 1, 0, 0], [1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 4, 1, 0, 1], [0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1], [0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1], [0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 2, 1, 1, 0], [0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 2, 1, 0, 0], [1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 4, 1, 0, 1], [0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 2, 1, 0, 1], [0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 6, 0, 0, 0], [0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 4, 0, 0, 0], [0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 4, 0, 0, 0], [1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 2, 1, 0, 0], [1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 4, 1, 0, 1], [1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 2, 0, 1, 1], [0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 6, 0, 0, 0], [1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 4, 1, 1, 1], [1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 2, 0, 0, 1], [0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 2, 1, 0, 0], [0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0], [1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 4, 1, 1, 0], [1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 4, 1, 0, 0], [0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 2, 1, 0, 0], [0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0], [1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 6, 0, 1, 0], [1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 6, 0, 0, 0], [0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 2, 1, 0, 0], [0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 6, 0, 0, 0], [0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 2, 1, 0, 0], [1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 4, 1, 0, 1], [1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 4, 1, 0, 1], [0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 6, 0, 0, 0], [1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 4, 1, 0, 1], [1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 4, 1, 0, 1], [1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 4, 1, 0, 0], [1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 4, 1, 0, 1], [1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 6, 0, 0, 0], [0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 4, 1, 0, 0], [0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 8, 0, 0, 1], [1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 4, 1, 0, 0], [1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 4, 1, 0, 1], [0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 2, 1, 0, 1], [0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 2, 1, 1, 0], [0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 2, 1, 0, 1], [0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 2, 1, 0, 0], [0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1], [0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0], [0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0], [1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 4, 1, 0, 1], [1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 4, 1, 0, 1], [1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 4, 1, 1, 1], [0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1], [1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 4, 1, 0, 1], [1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 4, 1, 1, 1], [1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 4, 1, 0, 1], [1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 4, 1, 1, 1], [0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 2, 1, 0, 1], [0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 8, 1, 0, 0], [0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0], [1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1], [1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 2, 1, 0, 1], [0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0], [0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 2, 1, 0, 0], [0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 2, 1, 0, 0], [0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0], [0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 2, 1, 0, 0], [1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 2, 1, 0, 0], [0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 5, 0, 0, 0], [0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1], [0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 2, 1, 0, 1], [0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 6, 0, 0, 0], [0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 4, 0, 0, 0]]\n",
      "[[0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 4, 1, 0, 1], [0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 4, 1, 0, 0], [0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1], [1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 2, 1, 0, 0], [1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 4, 1, 0, 0], [0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 2, 1, 0, 1], [1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 2, 1, 0, 1], [1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 6, 0, 0, 0], [1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 4, 1, 0, 1], [0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 2, 1, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "print(train_features)      \n",
    "print(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 4, 1, 1, 1, 1, 4, 4, 1, 1, 2, 4, 7, 7, 7, 2, 1, 4, 1, 2, 2, 1, 2, 6, 5, 5, 1, 1, 1, 6, 1, 1, 2, 4, 1, 1, 2, 4, 6, 6, 2, 6, 2, 1, 1, 7, 1, 1, 1, 1, 6, 5, 7, 1, 1, 2, 2, 2, 2, 4, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1, 2, 7, 4, 1, 1, 3, 7, 2, 2, 3, 7, 4, 2, 1, 7, 4, 2, 6, 5]\n",
      "[3, 3, 4, 1, 1, 2, 1, 6, 1, 7, 2]\n"
     ]
    }
   ],
   "source": [
    "print(train_labels)\n",
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>For your testing</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(train_features) == len(train_labels)\n",
    "assert len(train_features[0])==len(train_features[-1])\n",
    "assert train_features[2][12]==0 and train_labels[2]==4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "V2OlvNAicY4i"
   },
   "source": [
    "### Question 2: Distance Functions (2.0 marks)\n",
    "\n",
    "<b>Instructions</b>: Implement the four distance functions specified below. Use <b>only</b> the library imported below, i.e., <b>do not</b> use implementations from any other Python library. \n",
    "\n",
    "1. Eucledian distance\n",
    "2. Cosine distance\n",
    "3. Hamming distance \n",
    "4. Jaccard distance \n",
    "\n",
    "Each distance function takes as input\n",
    "- Two feature vectors\n",
    "\n",
    "and returns as output\n",
    "- The distance between the two feature vectors (float)\n",
    "\n",
    "**Note** for the purpose of this assignment we consider the numeric feature (legs) to be discretized already with each individual value belonging constituting a separate class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10593,
     "status": "ok",
     "timestamp": 1588139440049,
     "user": {
      "displayName": "Jey Han Lau",
      "photoUrl": "",
      "userId": "09065329932778503205"
     },
     "user_tz": -600
    },
    "id": "szPlY9PIcY4j",
    "outputId": "218560c5-6e80-4a8b-bfaf-5cb46b90f34c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# assume fv1 is features of each instance from test_features, while fv2 is those from train_features\n",
    "   \n",
    "# refered by: The University of Melbourne,(2021) w2-solution-21s1.ipynb (Version 1.0) [Source code]. https://canvas.lms.unimelb.edu.au/courses/105477/files/6869589?wrap=1\n",
    "def eucledian_distance(fv1, fv2): \n",
    "    return math.sqrt(sum([(fv1[i]-fv2[i])*(fv1[i]-fv2[i]) for i in range(len(fv1))]))\n",
    "    \n",
    "# refered by: The University of Melbourne,(2021) w2-solution-21s1.ipynb (Version 1.0) [Source code]. https://canvas.lms.unimelb.edu.au/courses/105477/files/6869589?wrap=1\n",
    "def cosine_distance(fv1, fv2):\n",
    "    return sum([fv1[i]*fv2[i] for i in range(len(fv1))]) / math.sqrt(sum([pow(value,2) for value in fv1])) * math.sqrt(sum([pow(value,2) for value in fv2]))\n",
    "        \n",
    "\n",
    "def hamming_distance(fv1, fv2):\n",
    "    ham_dist = 0\n",
    "    for i in range(len(fv1)):\n",
    "        if fv1[i] != fv2[i]:\n",
    "            ham_dist += 1        \n",
    "    return ham_dist\n",
    "    \n",
    "\n",
    "def jaccard_distance(fv1, fv2):\n",
    "    fv1_feature_num = 0\n",
    "    fv2_feature_num = 0\n",
    "    intersection = 0\n",
    "    \n",
    "    for value in fv1:\n",
    "        if value == 1:\n",
    "            fv1_feature_num += 1\n",
    "            \n",
    "    for value in fv2:\n",
    "        if value == 1:\n",
    "            fv2_feature_num += 1\n",
    "\n",
    "    for i in range(len(fv1)):\n",
    "        if fv1[i] == fv2[i] == 1:\n",
    "            intersection += 1\n",
    "            \n",
    "    return 1 - (intersection / (fv1_feature_num + fv2_feature_num - intersection))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JTt3T9fycY4p"
   },
   "source": [
    "<b>For your testing: </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PCkSP91lcY4q"
   },
   "outputs": [],
   "source": [
    "assert round(eucledian_distance([1,0],[0.5,1]),2)==1.12 \n",
    "assert jaccard_distance([1,1,1,1], [0,1,0,0])==0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zknFIccAcY40"
   },
   "source": [
    "### Question 3: KNN Classifier (4.0 marks)\n",
    "\n",
    "<b>Instructions</b>: Here, you implement your KNN classifier. It takes as input \n",
    "- training data features\n",
    "- training data labels\n",
    "- test data features\n",
    "- parameter K\n",
    "- distance function(s) based on which nearest neighbors will be identified\n",
    "\n",
    "It returns as output \n",
    "- the predicted labels for the test data\n",
    "\n",
    "**Voting stragegy** Your classifier will use majority voting (i.e., no distance weighting)\n",
    "\n",
    "**You should implement the classifier from scratch yourself**, i.e., <b> you must not</b> use an existing implementation in any Python library.\n",
    "\n",
    "**Ties**. Ties may occur when computing the K nearest neighbors, or when predicting the class based on the neighborhood. You may deal with ties whichever way you want (as long as you still use the requested distance functions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 919,
     "status": "ok",
     "timestamp": 1588139482398,
     "user": {
      "displayName": "Jey Han Lau",
      "photoUrl": "",
      "userId": "09065329932778503205"
     },
     "user_tz": -600
    },
    "id": "W6rdnrOXcY41",
    "outputId": "8d2391db-d5c0-4ea2-ea83-850e79bffd5c",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "def KNN(train_features, train_labels, test_features, k, dist_fun):\n",
    "    \n",
    "    predictions = np.array([], dtype = int)\n",
    "    \n",
    "    # calculate distance between each test features and training features\n",
    "    for test_feat in test_features:\n",
    "        distances = [] \n",
    "        for train_feat in train_features:\n",
    "            if id(dist_fun) == id(eucledian_distance):\n",
    "                distances.append(eucledian_distance(test_feat, train_feat))\n",
    "            if id(dist_fun) == id(cosine_distance):\n",
    "                distances.append(cosine_distance(test_feat, train_feat))\n",
    "            if id(dist_fun) == id(jaccard_distance):\n",
    "                rules_to_convert_legs(test_feat, train_feat)\n",
    "                distances.append(jaccard_distance(test_feat, train_feat))\n",
    "            if id(dist_fun) == id(hamming_distance):\n",
    "                rules_to_convert_legs(test_feat, train_feat)\n",
    "                distances.append(hamming_distance(test_feat, train_feat))\n",
    "          \n",
    "        # combines corresponding train labels and distance between each test feature and training features\n",
    "        match_labels = np.array(train_labels)\n",
    "        train_distances = np.array(distances)\n",
    "            \n",
    "        labels_dist = np.stack((match_labels, train_distances),axis = -1)\n",
    "            \n",
    "        # sort the array to find the first k labels and distance\n",
    "        # refered from: https://www.kite.com/python/answers/how-to-sort-the-rows-of-a-numpy-array-by-a-column-in-python\n",
    "        sorted_labels_dist = labels_dist[np.argsort(labels_dist[:,1])]\n",
    "        KNN = sorted_labels_dist[:k]\n",
    "        \n",
    "        KNN_labels = []  \n",
    "        for match in KNN:\n",
    "            KNN_labels.append(match[0])\n",
    "            \n",
    "        # find the mode in KNN labels, which is the prediction for the test feature\n",
    "        mode = stats.mode(KNN_labels)[0]\n",
    "            \n",
    "        predictions = np.append(predictions, mode)\n",
    "            \n",
    "    return predictions  \n",
    "\n",
    "    \n",
    "# rules to deal with legs \n",
    "# if the number of legs are the same, turn both fv1[12] and fv2[12], which are the position of legs feature, into 1\n",
    "# otherwise, turn fv1[12] to 0, fv2[12] to 1\n",
    "def rules_to_convert_legs(fv1, fv2):\n",
    "    if fv1[12] == fv2[12]:\n",
    "        fv1[12] == 1\n",
    "        fv2[12] == 1\n",
    "    else:\n",
    "        fv1[12] == 0\n",
    "        fv2[12] == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cWgLNH3LcY45"
   },
   "source": [
    "<b>For your testing:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert KNN([[1,1],[5,5],[1,2]], [1,0,1], [[1,1]], 1, eucledian_distance) == [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "th1NNkYZcY45"
   },
   "source": [
    "### Question 4: Evaluation (1.0 marks)\n",
    "**Instructions:** Write a function that computes the \"accuracy\" of your classifier. Given a set of predicted lables and a set of gold labels, it returns the fraction of correct labels over all predicted labels. \n",
    "\n",
    "**Example**: `The gold truth labels for four test instances are [1, 1, 1, 1]. A system predicted the labels [0, 1, 0, 0] for the same 4 instances. The accuracy of the system is 1/4 = 0.25\n",
    "`\n",
    "\n",
    "Your function will take as input \n",
    "- gold labels\n",
    "- predicted labels\n",
    "\n",
    "It returns as output\n",
    "- the accuracy value (float).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "colab_type": "text",
    "id": "F3V5AkC8cY48"
   },
   "outputs": [],
   "source": [
    "def accuracy(predict, gold):\n",
    "    predict = np.array(predict)\n",
    "    gold = np.array(gold)\n",
    "    num_matched_label = 0\n",
    " \n",
    "    for i in range(len(predict)):\n",
    "        if predict[i] == gold[i]:\n",
    "            num_matched_label += 1\n",
    "    \n",
    "    accuracy = round((num_matched_label / len(predict)),2)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xUwPHXMmcY49"
   },
   "source": [
    "<b>For your testing:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8hL-EnT-cY49"
   },
   "outputs": [],
   "source": [
    "assert accuracy([1, 1, 1, 1], [0, 1, 0, 1])==0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5: Applying your KNN classifiers to the Zoo Dataset (3.0 marks)\n",
    "\n",
    "**Using the functions you have implemented above, please**\n",
    "\n",
    "<b> 1. </b>\n",
    "For each of the distance functions you implemented in Question 2, construct four KNN classifiers with K=1, K=5, K=25, K=55. You will create a total of 16 (4 distance functions x 4 K values) classifiers.\n",
    "\n",
    "<b> 2. </b>\n",
    "Compute the test accuracy for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean\n",
      "0.82\n",
      "0.82\n",
      "0.64\n",
      "0.36\n",
      "Cosine\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.18\n",
      "Jaccard\n",
      "0.82\n",
      "0.82\n",
      "0.64\n",
      "0.45\n",
      "Hamming\n",
      "0.82\n",
      "0.82\n",
      "0.73\n",
      "0.45\n"
     ]
    }
   ],
   "source": [
    "# 1. Predict test labels with each KNN classifier\n",
    "classifier1 = KNN(train_features, train_labels, test_features, 1, eucledian_distance)\n",
    "classifier2 = KNN(train_features, train_labels, test_features, 5, eucledian_distance)\n",
    "classifier3 = KNN(train_features, train_labels, test_features, 25, eucledian_distance)\n",
    "classifier4 = KNN(train_features, train_labels, test_features, 55, eucledian_distance)\n",
    "\n",
    "classifier5 = KNN(train_features, train_labels, test_features, 1, cosine_distance)\n",
    "classifier6 = KNN(train_features, train_labels, test_features, 5, cosine_distance)\n",
    "classifier7 = KNN(train_features, train_labels, test_features, 25, cosine_distance)\n",
    "classifier8 = KNN(train_features, train_labels, test_features, 55, cosine_distance)\n",
    "\n",
    "classifier9 = KNN(train_features, train_labels, test_features, 1, jaccard_distance)\n",
    "classifier10 = KNN(train_features, train_labels, test_features, 5, jaccard_distance)\n",
    "classifier11 = KNN(train_features, train_labels, test_features, 25, jaccard_distance)\n",
    "classifier12 = KNN(train_features, train_labels, test_features, 55, jaccard_distance)\n",
    "\n",
    "classifier13 = KNN(train_features, train_labels, test_features, 1, hamming_distance)\n",
    "classifier14 = KNN(train_features, train_labels, test_features, 5, hamming_distance)\n",
    "classifier15 = KNN(train_features, train_labels, test_features, 25, hamming_distance)\n",
    "classifier16 = KNN(train_features, train_labels, test_features, 55, hamming_distance)\n",
    "\n",
    "# 2. Compute the accuracy scores \n",
    "accuracy_knn_euc_1 = accuracy(classifier1, test_labels)\n",
    "accuracy_knn_euc_5 = accuracy(classifier2, test_labels)\n",
    "accuracy_knn_euc_25 = accuracy(classifier3, test_labels)\n",
    "accuracy_knn_euc_55 = accuracy(classifier4, test_labels)\n",
    "\n",
    "accuracy_knn_cos_1 = accuracy(classifier5, test_labels)\n",
    "accuracy_knn_cos_5 = accuracy(classifier6, test_labels)\n",
    "accuracy_knn_cos_25 = accuracy(classifier7, test_labels)\n",
    "accuracy_knn_cos_55 = accuracy(classifier8, test_labels)\n",
    "\n",
    "accuracy_knn_jac_1 = accuracy(classifier9, test_labels)\n",
    "accuracy_knn_jac_5 = accuracy(classifier10, test_labels)\n",
    "accuracy_knn_jac_25 = accuracy(classifier11, test_labels)\n",
    "accuracy_knn_jac_55 = accuracy(classifier12, test_labels)\n",
    "\n",
    "accuracy_knn_ham_1 = accuracy(classifier13, test_labels)\n",
    "accuracy_knn_ham_5 = accuracy(classifier14, test_labels)\n",
    "accuracy_knn_ham_25 = accuracy(classifier15, test_labels)\n",
    "accuracy_knn_ham_55 = accuracy(classifier16, test_labels)\n",
    "\n",
    "\n",
    "print(\"Euclidean\")\n",
    "print(accuracy_knn_euc_1)\n",
    "print(accuracy_knn_euc_5)\n",
    "print(accuracy_knn_euc_25)\n",
    "print(accuracy_knn_euc_55)\n",
    "print(\"Cosine\")\n",
    "print(accuracy_knn_cos_1)\n",
    "print(accuracy_knn_cos_5)\n",
    "print(accuracy_knn_cos_25)\n",
    "print(accuracy_knn_cos_55)\n",
    "print(\"Jaccard\")\n",
    "print(accuracy_knn_jac_1)\n",
    "print(accuracy_knn_jac_5)\n",
    "print(accuracy_knn_jac_25)\n",
    "print(accuracy_knn_jac_55)\n",
    "print(\"Hamming\")\n",
    "print(accuracy_knn_ham_1)\n",
    "print(accuracy_knn_ham_5)\n",
    "print(accuracy_knn_ham_25)\n",
    "print(accuracy_knn_ham_55)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6: Discussion (3.0 marks)\n",
    "1. (a) Which parameter K resulted in the best performance? (b) Why? (c) What could be done to improve those classifiers that are currently performing poorly?\n",
    "\n",
    "2. The results of KNN with Euclidean distance and KNN with Cosine distance are remarkably similar. Why is that so? Referring to the definitions of the distance functions.\n",
    "\n",
    "<b>Each question should be answered in no more than 2-3 sentences.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1(a) K = 1 or K = 5 resulted in tbe best performance\n",
    "\n",
    "1(b) The smaller K means the narrower scope of neighbours to the test instance, which circles the K most similar/least different train instances around irrespective of which approach to calculate distances. So the result with smaller K would be better.\n",
    "\n",
    "1(c) For the Cosines Distance, maybe we could replace features by various numerical values so the results would be better. Boolean values would cause dramatical bias since the multiplication of Cosine Distance would be significantly affected by zeros, causing each training instance is super close to the test instance. So the program doesn't know which training instance is exactly similar to the test instance. Numerical data would better help Cosine Distance to normalize the magnitude, then find the reasonable KNN to decide the classifier.\n",
    "\n",
    "2 My results of this two approaches are quite different, since I keep the numbers in legs to calculate. But Euclidean Distance mainly uses abstraction and addition so the distance was not affected a lot, while Cosines Distance uses only multiplication so the effect of magnitude normalization would be offset.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "word-similarity.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
