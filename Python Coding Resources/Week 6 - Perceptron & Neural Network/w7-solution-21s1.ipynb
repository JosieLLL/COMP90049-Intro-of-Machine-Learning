{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  The University of Melbourne, School of Computing and Information Systems\n",
    "# COMP90049 Introduction to Machine Learning, 2021 Semester 1\n",
    "\n",
    "## Week 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE:  You will need the newer (18.1) build of `scikit-learn` for its neural network support."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Exercise 1.\n",
    "The Multilayer Perceptron is available from (newer builds of) `scikit-learn` as `sklearn.neural_network.MLPClassifier`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.(a) \n",
    "Build a default Multilayer Perceptron to classify the `Iris` data. Evaluate its cross-validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (150, 4) y: {0, 1, 2}\n",
      "corss-val acc: 0.9800000000000001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(max_iter=2000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "print('X:', X.shape, 'y:', set(y))\n",
    "\n",
    "\n",
    "clf = MLPClassifier(max_iter=2000)\n",
    "\n",
    "print('corss-val acc:', np.mean(cross_val_score(clf, X, y, cv=5)))\n",
    "clf.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "x2 = SelectKBest(chi2, k=1)\n",
    "\n",
    "X_x2 = x2.fit_transform(X,y)\n",
    "# X_test_x2 = x2.transform(X_test)\n",
    "print(x2.get_support(indices=True))\n",
    "# for feat_num in x2.get_support(indices=True):\n",
    "#     print(vectoriser.get_feature_names()[feat_num])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.(b) \n",
    "Check the `coefs_` and `n_layers_` attributes of the fitted classifier to examine the resulting neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 1.15939024e-11,  7.71780289e-02,  3.74601840e-02,\n",
      "        -7.36068448e-02,  1.00509466e-01,  3.22748607e-02,\n",
      "        -3.06676194e-02,  1.09432226e-01,  2.02062686e-01,\n",
      "         3.91995196e-01, -1.99887338e-01,  7.58646478e-03,\n",
      "        -1.89552265e-02, -2.30749332e-05, -1.26992499e-01,\n",
      "         1.18487425e-01,  2.19482443e-01,  3.02801699e-01,\n",
      "         6.08882107e-13,  1.99024769e-01,  1.54168027e-01,\n",
      "         5.65867174e-12,  3.51405015e-01,  1.17037407e-01,\n",
      "         2.18891514e-01, -4.19571060e-02, -1.20112405e-02,\n",
      "        -1.85932650e-02,  1.37859665e-01,  2.50412347e-02,\n",
      "        -1.31343677e-05,  1.14789274e-01, -3.46352061e-02,\n",
      "        -1.09519534e-04, -3.93294434e-02,  2.64504672e-01,\n",
      "         2.36059011e-01, -2.43128237e-06, -8.82597582e-10,\n",
      "         2.08477396e-01,  2.66508825e-01, -1.77133106e-02,\n",
      "         1.38526169e-01,  4.22180667e-01, -1.46373930e-02,\n",
      "         1.77158349e-01,  1.71178592e-01,  1.03729732e-01,\n",
      "         9.30197021e-02, -3.16010897e-13,  2.95790822e-01,\n",
      "         2.52154970e-01, -3.39121613e-02,  1.36456496e-01,\n",
      "        -9.85971954e-03, -2.31824475e-06,  1.75716867e-01,\n",
      "        -9.85898049e-05, -2.46959461e-05, -7.62442026e-02,\n",
      "         1.67018427e-01, -4.91472451e-05, -1.08253007e-02,\n",
      "         1.85869469e-01, -1.93094287e-03, -2.76121123e-10,\n",
      "         1.31857908e-01,  1.24538474e-01,  8.32948552e-02,\n",
      "         2.12502234e-01,  9.67604590e-02,  1.20213154e-01,\n",
      "         6.55174760e-02, -1.12195390e-05,  1.06355822e-01,\n",
      "        -6.57739295e-03,  1.62881472e-02,  9.63220330e-02,\n",
      "        -4.41456880e-13, -1.00108540e-02,  1.95214259e-01,\n",
      "         2.24549809e-01,  2.69091341e-01, -2.83326959e-02,\n",
      "         2.72109503e-01, -3.81916817e-02,  3.66413403e-03,\n",
      "         2.92336248e-10,  2.61743045e-01,  1.21759989e-01,\n",
      "         4.84139264e-02,  2.80865824e-01,  3.69291058e-02,\n",
      "        -2.25895525e-03,  2.20383641e-01, -2.80229295e-01,\n",
      "         1.14575886e-01, -2.50641887e-01, -9.69612354e-03,\n",
      "        -1.84213932e-05],\n",
      "       [-1.55453083e-12,  1.00118581e-01,  4.29064670e-01,\n",
      "        -3.80317558e-01,  3.79693511e-02, -1.11240139e-01,\n",
      "        -6.14413582e-02,  3.54585092e-01,  2.79129768e-01,\n",
      "         5.97844316e-02, -3.32035689e-01,  4.21572412e-01,\n",
      "        -1.50803172e-01, -5.45764393e-04, -3.59499273e-02,\n",
      "        -5.80226833e-03,  5.17856551e-02,  3.99754822e-01,\n",
      "         1.09222770e-07, -3.40924920e-01, -6.69368723e-02,\n",
      "        -7.55108613e-06,  7.22205949e-02, -1.12710761e-01,\n",
      "         2.10124376e-01,  6.84931454e-02, -3.29924052e-02,\n",
      "        -2.57470759e-02,  1.68053920e-02, -4.84064505e-02,\n",
      "        -1.78535314e-04, -2.56237936e-01, -1.87931357e-02,\n",
      "        -2.81615794e-07,  6.76837338e-02,  3.69323964e-01,\n",
      "        -1.89776513e-02, -5.58897235e-03, -2.34391054e-10,\n",
      "         1.73057742e-01, -1.25668281e-01, -2.09463093e-02,\n",
      "         1.91087455e-01, -4.30824071e-01, -3.83178118e-03,\n",
      "         8.90308766e-02,  2.13680834e-01,  1.81669009e-02,\n",
      "        -6.51421759e-02,  1.67481173e-11,  3.53654985e-01,\n",
      "         3.84374160e-01, -7.03740380e-02, -2.65215547e-01,\n",
      "        -5.85941594e-03,  4.36470183e-04,  2.89890244e-01,\n",
      "         9.66291063e-04,  2.09719685e-04, -4.16122803e-01,\n",
      "         1.74857667e-02,  3.45748291e-03, -2.40947692e-01,\n",
      "        -3.46758839e-01,  8.10878642e-05, -7.50971487e-03,\n",
      "         2.79244311e-01,  9.06043194e-02, -2.10825658e-01,\n",
      "        -2.50863339e-01, -1.16954049e-01,  3.68628070e-01,\n",
      "         1.68776361e-01, -1.36018856e-08, -7.05654752e-02,\n",
      "         7.90554299e-03,  2.86413754e-01,  3.57554397e-01,\n",
      "        -1.75680798e-04,  1.76475953e-03,  5.00063697e-02,\n",
      "         1.41867256e-01,  4.09580646e-01, -1.84976275e-02,\n",
      "        -2.94174438e-02,  1.80619255e-02,  1.69626639e-01,\n",
      "        -2.66172459e-13,  2.04515148e-01, -1.10318564e-02,\n",
      "         3.59918523e-01,  2.45438787e-01, -1.89807409e-01,\n",
      "         1.42763005e-04,  2.49553910e-01, -3.09030014e-02,\n",
      "         1.47051426e-01,  3.56186717e-02, -1.22257079e-02,\n",
      "         5.77955522e-07],\n",
      "       [-7.23527198e-04,  1.92308684e-01, -2.83205131e-01,\n",
      "         4.18885611e-01,  1.13938487e-01,  2.99365445e-01,\n",
      "         3.03045081e-02, -3.81064584e-01, -7.22150103e-02,\n",
      "        -3.94188367e-01,  4.47105987e-01, -1.15823874e-01,\n",
      "         3.39529758e-01, -7.01254098e-03,  1.68675874e-01,\n",
      "         3.19979713e-02, -3.58587786e-01, -4.36094273e-01,\n",
      "        -2.55736094e-03,  4.41296499e-01,  1.99793794e-01,\n",
      "        -3.52769112e-04, -2.90403939e-01, -1.03459951e-01,\n",
      "        -3.62325567e-01, -1.85547732e-01, -1.37187835e-02,\n",
      "        -1.75502483e-02,  6.63166184e-02,  2.33771517e-01,\n",
      "         1.88773247e-10,  7.95693553e-02, -1.57853390e-02,\n",
      "        -2.82032955e-10, -1.47872682e-01, -4.30952459e-01,\n",
      "        -2.19387803e-01, -2.03230721e-11, -7.42902359e-09,\n",
      "        -2.82662836e-01, -5.25180938e-02, -2.42320024e-02,\n",
      "        -2.15672996e-01,  5.15572604e-01,  4.76217586e-04,\n",
      "         1.02874833e-01, -1.27246820e-01,  6.32717260e-02,\n",
      "         3.60167940e-01, -6.90954037e-03, -4.43862556e-01,\n",
      "        -4.23211512e-01, -1.79477169e-02,  1.33275008e-01,\n",
      "        -3.29867451e-03, -7.95725552e-03, -3.64756727e-01,\n",
      "        -4.98066462e-03, -7.17662124e-04,  2.60343107e-01,\n",
      "        -1.19338341e-01, -1.44256826e-05,  1.09217597e-01,\n",
      "         1.74600084e-01, -2.40420978e-04, -5.21780335e-08,\n",
      "        -2.46460334e-01,  1.96232972e-01,  2.03784650e-01,\n",
      "        -2.29670040e-01,  9.81347244e-02, -4.38439240e-01,\n",
      "         1.05621591e-01, -6.90281228e-03, -1.35750247e-01,\n",
      "         2.51713486e-10,  1.77823308e-01, -3.89923190e-01,\n",
      "         1.01725109e-11,  5.18988030e-08, -3.41914899e-02,\n",
      "         4.40212906e-02, -4.42153033e-01, -7.03550885e-02,\n",
      "        -1.19151009e-01,  2.95023745e-01,  1.47808865e-01,\n",
      "        -6.76019973e-13, -3.18475864e-01, -1.20400587e-01,\n",
      "        -2.58955178e-01, -3.47139158e-01, -4.04305875e-02,\n",
      "         1.61412166e-03,  3.33483403e-02,  3.90949522e-01,\n",
      "         2.59766100e-01,  2.61355414e-01, -3.08422382e-03,\n",
      "        -5.64812908e-05],\n",
      "       [ 1.92386226e-03,  1.63049771e-01, -3.08047124e-01,\n",
      "         5.20547829e-01, -5.34887864e-02, -4.42477603e-02,\n",
      "         3.03849586e-01, -3.77772500e-01, -1.60092340e-01,\n",
      "        -4.16565804e-01,  5.04817458e-01, -3.74112120e-01,\n",
      "         3.87414404e-01,  7.96766676e-04,  1.01318466e-02,\n",
      "        -4.55380018e-01,  4.36569978e-02, -5.21395678e-01,\n",
      "         1.27146495e-05, -4.67938779e-02,  3.04871445e-01,\n",
      "         3.26310417e-09, -4.26991247e-01,  4.80145233e-02,\n",
      "        -3.83344758e-01, -1.46052730e-01, -5.87867254e-02,\n",
      "        -1.47118960e-02,  1.85567025e-01,  5.12769156e-01,\n",
      "         2.46354512e-03,  2.69419402e-01, -2.30459530e-04,\n",
      "        -6.44935772e-03, -2.47770333e-01, -4.70026371e-01,\n",
      "        -1.33499999e-01,  1.01320594e-02,  3.19316296e-04,\n",
      "        -3.41441874e-01, -2.89248697e-01, -1.77284479e-02,\n",
      "        -3.29413790e-01,  5.04242435e-01, -8.14432255e-03,\n",
      "         1.73335689e-01,  1.46853273e-01,  2.20958196e-01,\n",
      "         4.62066533e-02,  2.44540317e-05, -5.02422312e-01,\n",
      "        -4.51604938e-01, -1.51449581e-02,  1.12600974e-01,\n",
      "        -8.54504584e-04,  5.81031799e-03, -1.67909324e-01,\n",
      "         2.03999072e-15,  4.10531239e-03,  5.56348361e-01,\n",
      "         2.09023559e-01,  4.17307724e-04, -1.25283798e-01,\n",
      "         4.10011726e-01, -1.04202085e-02,  2.94133029e-06,\n",
      "        -1.55146446e-01,  3.06397629e-01,  4.19718822e-01,\n",
      "        -2.14429210e-02,  3.41717145e-01, -4.08726283e-01,\n",
      "        -1.94579813e-01, -7.29453909e-05, -1.38768224e-01,\n",
      "         8.38483283e-08, -3.63555559e-01, -3.45828888e-01,\n",
      "        -4.86880346e-04,  1.10384450e-04, -1.74054670e-01,\n",
      "        -3.90581333e-01, -5.44840766e-01, -1.67027657e-01,\n",
      "         5.94189807e-02,  1.67542527e-01, -1.89067040e-01,\n",
      "        -3.85255505e-05, -3.38378065e-01,  5.78130737e-02,\n",
      "        -3.27421661e-01, -3.74086594e-01,  2.05810908e-01,\n",
      "        -4.32885459e-05, -1.19394872e-01,  2.28851614e-01,\n",
      "        -1.24177345e-01,  4.78768471e-01, -2.87952922e-03,\n",
      "        -6.41447565e-05]]), array([[-4.38502327e-05, -9.10168449e-13,  2.68514188e-03],\n",
      "       [-8.05861858e-02,  4.03550290e-03,  6.29963433e-02],\n",
      "       [ 3.52961912e-01, -2.46255828e-01,  3.96782221e-02],\n",
      "       [-2.24740141e-01, -3.45473652e-01,  3.31697615e-01],\n",
      "       [-7.97077639e-02, -1.56367415e-01,  1.34434177e-01],\n",
      "       [-1.87667199e-01,  1.31036050e-01,  2.46044174e-01],\n",
      "       [ 9.07086816e-02, -1.54421762e-01,  2.76307187e-01],\n",
      "       [ 4.45164124e-01, -4.49728691e-01, -2.79090762e-01],\n",
      "       [ 2.84972654e-01,  2.65468047e-01, -1.85631042e-02],\n",
      "       [ 4.03670931e-01,  5.10740684e-01, -3.66664849e-02],\n",
      "       [-3.65671988e-01, -5.77440036e-01,  5.67796081e-01],\n",
      "       [ 4.63963580e-01,  2.53455257e-01, -5.00692084e-01],\n",
      "       [-3.34063309e-01, -3.11772069e-02,  1.98846911e-01],\n",
      "       [ 7.10537071e-03, -1.40889474e-10,  9.00011066e-04],\n",
      "       [-2.12125652e-02, -2.24242660e-01, -1.95284752e-01],\n",
      "       [ 1.10870820e-01,  4.69471752e-01, -3.27839591e-01],\n",
      "       [ 1.51922411e-01, -4.28004066e-01, -1.61021660e-02],\n",
      "       [ 4.47902114e-01,  5.50933646e-01, -5.54544129e-01],\n",
      "       [-8.16658368e-05,  6.64736707e-03,  8.14581722e-03],\n",
      "       [-3.34030828e-01,  8.03642840e-02,  4.01160778e-02],\n",
      "       [-1.65962171e-01, -1.20945855e-01,  1.98945708e-01],\n",
      "       [ 3.26845779e-03,  7.13222470e-03, -2.02813616e-03],\n",
      "       [ 2.48237461e-01,  2.90593152e-01, -2.54509524e-01],\n",
      "       [-1.33992077e-01, -6.99377252e-02,  9.46111813e-02],\n",
      "       [ 4.44637326e-01, -2.02559377e-01,  1.27969678e-02],\n",
      "       [-2.00720720e-01, -2.54246388e-01, -5.15332457e-02],\n",
      "       [-3.71853911e-06,  8.65121520e-03,  1.14756922e-10],\n",
      "       [-9.61112564e-03, -7.01027241e-04,  1.06300478e-03],\n",
      "       [-2.00031035e-01, -1.76265452e-01, -1.20962715e-01],\n",
      "       [-1.72826412e-01, -1.52239645e-01,  9.28393242e-02],\n",
      "       [-8.88496952e-05,  1.72016781e-05, -2.40286890e-08],\n",
      "       [-3.93200069e-01,  2.46361739e-01,  3.53346389e-02],\n",
      "       [ 5.61008220e-09,  1.58307634e-03,  1.51855692e-04],\n",
      "       [-7.21143825e-03, -2.27988246e-05, -3.81877509e-13],\n",
      "       [-1.78575911e-01, -2.10700240e-01,  1.02155752e-01],\n",
      "       [ 4.69472658e-01,  5.50223289e-01, -5.64920229e-01],\n",
      "       [ 2.29362938e-01,  2.77108832e-01, -3.92623878e-01],\n",
      "       [-9.31013620e-13,  6.92549121e-03,  4.14574311e-04],\n",
      "       [-5.24722237e-04,  8.33736798e-03,  5.72707207e-07],\n",
      "       [ 4.11104276e-02,  1.73014727e-01, -4.29119245e-01],\n",
      "       [ 2.78774543e-01,  3.03356215e-02, -3.23794059e-01],\n",
      "       [ 2.29950891e-02, -2.28498694e-02, -1.58568927e-02],\n",
      "       [ 3.61470942e-01,  1.62939881e-01, -4.17183175e-01],\n",
      "       [-4.78545462e-01,  1.84746585e-01,  4.64822449e-01],\n",
      "       [ 4.83866235e-03, -2.66680280e-03, -5.01245443e-10],\n",
      "       [-1.72282105e-01, -8.33100077e-02,  2.42266189e-02],\n",
      "       [ 3.16930192e-01, -1.93113890e-01,  1.35134681e-01],\n",
      "       [-1.72224451e-01,  3.93243145e-02,  2.16274980e-01],\n",
      "       [-2.35435780e-01,  2.01654463e-01,  5.44789447e-02],\n",
      "       [ 7.72593005e-03,  6.53700104e-03, -5.41473444e-04],\n",
      "       [ 5.19151588e-01,  4.67614562e-01, -5.73410303e-01],\n",
      "       [ 4.72148206e-01,  5.07040114e-01, -5.83505019e-01],\n",
      "       [ 1.01947250e-02, -1.50903952e-02,  6.11021351e-03],\n",
      "       [-3.32882839e-01,  6.42405942e-03, -1.26764966e-01],\n",
      "       [-1.08488696e-03, -7.62874019e-04,  2.45145274e-08],\n",
      "       [-6.23391903e-04, -1.82229289e-04,  8.00029143e-13],\n",
      "       [ 2.75716263e-01,  1.12317126e-01, -4.21589860e-01],\n",
      "       [-5.25771566e-09,  1.76653278e-07,  4.25702977e-03],\n",
      "       [-2.09556120e-03,  1.48823043e-05,  9.63283259e-03],\n",
      "       [-5.36135362e-02, -3.98524009e-01,  3.84849096e-01],\n",
      "       [ 3.86739466e-02, -2.42837628e-01,  1.32800147e-01],\n",
      "       [ 6.14010165e-07,  5.92057729e-05, -6.04990835e-03],\n",
      "       [ 1.50827503e-01,  1.36003384e-02, -1.81546002e-01],\n",
      "       [-4.07375087e-01,  1.24767156e-01,  3.45998125e-01],\n",
      "       [-4.40148409e-04,  2.45967845e-08,  1.29056453e-04],\n",
      "       [-3.46126223e-07, -9.28248647e-13, -3.35975305e-12],\n",
      "       [ 3.26931365e-01, -3.93614840e-02, -4.06614328e-01],\n",
      "       [-2.33820820e-01,  1.05637315e-02,  4.05955846e-02],\n",
      "       [-3.56691262e-01, -3.59375525e-02,  2.97528060e-01],\n",
      "       [ 5.65829259e-03,  8.53803416e-02, -1.05691114e-04],\n",
      "       [-2.49281711e-02, -8.54548271e-02,  1.63901907e-01],\n",
      "       [ 4.42671521e-01, -4.44318709e-01, -2.53385024e-01],\n",
      "       [ 2.60687827e-01, -8.73893794e-02,  1.02320878e-01],\n",
      "       [-1.87390845e-03,  3.67058787e-04, -1.64268785e-05],\n",
      "       [ 4.39680941e-02,  1.23571125e-01,  2.87533830e-02],\n",
      "       [-1.05475031e-04,  5.61577565e-03,  3.79534591e-06],\n",
      "       [-2.69231183e-02,  1.41131420e-01, -2.67924418e-01],\n",
      "       [ 4.44181320e-01, -4.76957644e-01, -1.83816967e-01],\n",
      "       [ 3.29196904e-03,  6.58704358e-03,  1.19992815e-03],\n",
      "       [-1.10636716e-03,  6.22135253e-03, -1.25561355e-06],\n",
      "       [ 2.11051547e-01,  1.52998671e-01, -1.23069049e-01],\n",
      "       [ 4.06213283e-02, -1.12151797e-01, -1.86115989e-01],\n",
      "       [ 4.32499724e-01, -6.03316032e-02, -6.43580209e-01],\n",
      "       [-1.17460051e-01,  2.15214373e-01,  2.29071200e-01],\n",
      "       [ 1.61992483e-01,  8.58637542e-02, -2.04275832e-01],\n",
      "       [-3.86441039e-01,  2.56930969e-02,  1.62707415e-01],\n",
      "       [ 2.40793406e-02,  1.60402996e-01, -3.32245900e-02],\n",
      "       [-7.20467252e-11,  5.53233949e-07,  1.08210215e-03],\n",
      "       [ 3.50777697e-01,  3.35655182e-01, -3.48155917e-01],\n",
      "       [ 9.52486783e-02,  1.66749927e-01,  1.46485149e-01],\n",
      "       [ 3.10643968e-01, -3.68098284e-01, -9.76217651e-02],\n",
      "       [ 3.70972747e-01,  3.60442264e-01, -3.66320808e-01],\n",
      "       [-4.35500373e-02,  1.84823353e-01, -1.24944199e-01],\n",
      "       [ 8.54998811e-11, -9.38557933e-03,  1.43080474e-12],\n",
      "       [ 2.08751462e-01,  2.24055716e-01,  1.54464883e-01],\n",
      "       [-5.48968809e-02, -6.57988411e-01,  5.67949424e-01],\n",
      "       [-1.81350940e-01,  1.79569091e-01,  2.75731128e-02],\n",
      "       [-3.41959065e-01, -5.77342212e-01,  1.87095425e-01],\n",
      "       [-6.82643851e-03, -3.73587246e-03,  3.29547668e-06],\n",
      "       [-5.79818126e-08, -3.21334616e-03, -3.05793009e-05]])]\n",
      "parameter shapes: [(4, 100), (100, 3)]\n",
      "num layers: 3\n"
     ]
    }
   ],
   "source": [
    "print(clf.coefs_)\n",
    "print('parameter shapes:',[p.shape for p in clf.coefs_])\n",
    "print('num layers:', clf.n_layers_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.\n",
    "One important issue with this Multilayer Perceptron is that it is sensitive to the scale of the input attribute values.\n",
    "### Exercise 2.(a) \n",
    "Read up on the `StandardScaler` , and re-scale the `Iris` data so that each attribute has a *mean* of 0 and a *variance* of 1. Evaluate and examine the resulting neural network built on the re-scaled data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corss-val cheating standardised features acc: 0.9733333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "clf = MLPClassifier(max_iter=2000)\n",
    "#it is cheating because the mean and variance are estimated using both training and test data\n",
    "print('corss-val cheating standardised features acc:', np.mean(cross_val_score(clf, scaler.fit_transform(X), y, cv=5))) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.(c) \n",
    "(Harder) Calculating the _mean_ and _variance_ on the entire data set (before splitting into train/test sets) is cheating slightly. Write a re-scale function that calculates the scaling factors for the training data, and applies the scaler to the test data. Then, write a wrapper function that uses this to cross-validate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corss-val noncheating standardised features acc: 0.9733333333333334\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(max_iter=2000)\n",
    "#this way we don't cheat read more on pipelines https://scikit-learn.org/stable/modules/compose.html\n",
    "pipeline = Pipeline([('transformer', scaler), ('estimator', clf)])\n",
    "print('corss-val noncheating standardised features acc:', np.mean(cross_val_score(pipeline, X, y, cv=5)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*You might not see reduction in performance for the noncheating method, but in general it is best to standardise only the training data (fit_transform), and then apply the transformation to the test data (transform).*\n",
    "\n",
    "*Also you didn't see improvements with standardisation, which might be the result of the neural network not being tuned well in terms of regularisation, and number/size of the layers.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3 \n",
    "You can coerce the Multilayer Perceptron to have specificallyâ€“sized hidden layers using the *hidden_layer_sizes* parameter.\n",
    "### Exercise 3.(a) \n",
    "Train a Multilayer Perceptron on the two-class `Abalone` data, and examine the resulting neural\n",
    "network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (4177, 7) y: {0, 1}\n",
      "[array([[-1.31531103e-01, -1.32771636e-01, -1.02266411e-01,\n",
      "         2.42490711e-01,  7.20822175e-02, -1.35244147e-52,\n",
      "         8.22294931e-03, -8.60203095e-02,  7.94626538e-02,\n",
      "         1.14050527e-47, -1.34975356e-01, -8.99679142e-02,\n",
      "         1.20059377e-01, -6.87712488e-02, -1.04573503e-78,\n",
      "         1.89503383e-01, -1.03544470e-77, -4.25461736e-74,\n",
      "         6.97353684e-02, -3.07459947e-02,  1.49052333e-52,\n",
      "         8.55666614e-02, -1.08541490e-01, -1.39666397e-44,\n",
      "        -1.95738294e-59,  5.57488029e-76,  1.10524837e-01,\n",
      "        -6.67819808e-02, -2.70948010e-02,  6.48838814e-02,\n",
      "        -1.56177216e-55,  2.25389531e-01,  1.18196754e-01,\n",
      "         2.24082255e-01,  1.78615151e-01,  6.38794858e-02,\n",
      "        -6.51296457e-02,  2.28653142e-01, -4.04783595e-02,\n",
      "         1.92348927e-01, -1.28817640e-01, -6.10068610e-02,\n",
      "        -4.20590355e-02, -5.73435035e-67, -3.24413673e-53,\n",
      "        -1.59615091e-01,  5.03988384e-02,  1.60344366e-01,\n",
      "         1.64717957e-01,  3.58557392e-02, -7.28938936e-02,\n",
      "        -2.14866304e-01, -1.68562768e-78,  1.10810488e-01,\n",
      "        -1.49772235e-01, -1.22714740e-01,  1.20828245e-01,\n",
      "         2.88567306e-01, -2.85872904e-01,  9.01827519e-03,\n",
      "         2.01246288e-40, -2.85949489e-01, -2.22039085e-02,\n",
      "         8.06158321e-02,  1.08590285e-77, -5.49521790e-03,\n",
      "         5.26070136e-71,  1.82920448e-03,  2.46363288e-02,\n",
      "         1.13358376e-02, -6.67988046e-66, -1.22454598e-01,\n",
      "        -7.39899456e-63, -4.76506737e-02,  2.45248686e-01,\n",
      "        -3.27275141e-02, -9.08695782e-02,  6.94968299e-02,\n",
      "         3.13244806e-01, -1.02434891e-01, -4.10146266e-02,\n",
      "         2.69214732e-01, -1.20741340e-46,  1.43898899e-01,\n",
      "         3.30609806e-01, -1.78114098e-01, -5.12664480e-79,\n",
      "         3.04676876e-01, -7.48750646e-03,  3.24234755e-01,\n",
      "         1.05031157e-01,  1.69954338e-01,  2.18277786e-69,\n",
      "        -2.98819573e-02, -5.89074431e-02,  8.82153874e-42,\n",
      "         5.13432385e-02,  1.72612197e-01, -5.68269106e-02,\n",
      "        -6.87342466e-02],\n",
      "       [ 1.16363733e-01,  7.18480885e-02, -1.20079684e-01,\n",
      "         4.45061095e-02,  2.57045708e-02,  7.22731592e-66,\n",
      "         2.75063416e-01,  8.16585589e-02,  1.69179702e-01,\n",
      "         1.10024300e-57,  1.13421093e-01,  4.74582196e-02,\n",
      "         2.07402519e-01, -4.62560995e-02,  6.19956211e-38,\n",
      "         2.38363869e-01, -3.12975076e-78,  2.65041157e-43,\n",
      "         2.77518512e-01, -1.43096996e-01,  2.29567770e-60,\n",
      "        -2.97888184e-01,  9.11686685e-02, -1.83473997e-59,\n",
      "         1.68350706e-61, -8.44114019e-57, -5.89838783e-02,\n",
      "        -1.29157647e-01,  4.98901612e-02, -7.75791874e-02,\n",
      "         1.11934831e-80,  1.81269661e-01,  1.84842013e-01,\n",
      "         6.68500576e-02, -7.45438112e-02, -1.65296902e-01,\n",
      "        -1.91858627e-01,  2.13667995e-01,  1.06196127e-01,\n",
      "        -1.09608520e-01,  1.74064448e-01, -2.34296509e-01,\n",
      "        -1.38201047e-01,  2.69988547e-72,  2.01300140e-81,\n",
      "         1.59318926e-01,  1.57375299e-01,  3.08627620e-01,\n",
      "         2.09002322e-01,  7.97278258e-04, -1.20312372e-01,\n",
      "        -2.42991108e-02,  2.72177633e-60,  9.84118234e-02,\n",
      "         1.18709994e-01, -1.01457308e-01,  1.82900920e-01,\n",
      "         2.15545925e-01,  9.85723194e-02, -1.52325851e-01,\n",
      "        -1.68734607e-73,  3.66288524e-02,  1.78701051e-01,\n",
      "         2.77007495e-03, -1.24231625e-49, -2.29925630e-02,\n",
      "         3.81765434e-42, -1.10254587e-03, -1.56131734e-02,\n",
      "        -9.85970140e-02,  1.35255652e-51,  5.39172739e-02,\n",
      "        -1.72720536e-50,  9.93350923e-02,  6.03149657e-02,\n",
      "         1.80625347e-01,  8.89496588e-02,  1.55420440e-01,\n",
      "         1.32865761e-01,  2.42748993e-03, -5.81986005e-02,\n",
      "        -2.34909870e-01, -1.31416000e-69,  1.73607866e-01,\n",
      "        -1.24334383e-01,  2.67855415e-01,  1.99169387e-74,\n",
      "        -6.36943297e-02,  1.09163882e-01,  1.18553644e-01,\n",
      "         3.12248099e-01, -2.34283562e-01, -2.18578355e-75,\n",
      "        -1.12077323e-01, -5.99895287e-02, -2.12683932e-80,\n",
      "         1.63081162e-01, -5.75594622e-02, -1.22309496e-01,\n",
      "         1.34606132e-01],\n",
      "       [-9.99202983e-02,  2.63773197e-01, -1.18416693e-02,\n",
      "        -1.76363543e-01, -1.26506132e-01,  3.49581663e-78,\n",
      "         1.33792624e-02, -3.28578751e-01,  2.65333731e-01,\n",
      "         6.00407221e-66,  2.60147432e-01,  4.53617621e-02,\n",
      "        -2.25855504e-02, -3.92970960e-01, -3.87603741e-77,\n",
      "         4.55383848e-01,  1.82797979e-75,  8.48692741e-83,\n",
      "         8.62775743e-02, -2.12361267e-01,  3.68525008e-74,\n",
      "         4.39922733e-02, -4.88293561e-01, -5.63743996e-67,\n",
      "         3.00507293e-71, -2.91241943e-77,  3.75454488e-02,\n",
      "        -4.57098130e-02,  2.71545933e-01,  5.20873189e-02,\n",
      "         8.69266022e-55, -4.81411805e-01, -4.40687331e-03,\n",
      "        -5.34692852e-01, -3.93180542e-01, -3.51330682e-01,\n",
      "        -1.52038657e-01,  1.23876453e-01,  6.91082589e-02,\n",
      "        -1.93552287e-02,  6.83130219e-02, -4.98868332e-01,\n",
      "         1.01218115e-01,  2.51108487e-64, -4.78989897e-42,\n",
      "         2.68956752e-01, -4.50313935e-03,  8.61525876e-02,\n",
      "         5.30763125e-02, -1.70156000e-01,  1.50570656e-02,\n",
      "         4.40538891e-01, -1.05033777e-82, -3.92145785e-01,\n",
      "         5.51899831e-01,  3.67468066e-01,  1.74969596e-01,\n",
      "        -2.05073299e-01, -5.56603753e-02,  1.17990588e-01,\n",
      "         5.53259653e-48,  7.21197868e-02, -1.24738765e-01,\n",
      "         4.64851290e-01,  1.44644738e-81,  9.14405417e-02,\n",
      "        -9.45021652e-75,  5.06456329e-02, -2.94235391e-01,\n",
      "        -6.53966151e-01,  1.58879838e-75, -2.37271570e-01,\n",
      "        -8.91351933e-50, -4.70431435e-01, -1.21699810e-01,\n",
      "        -3.91820661e-01, -2.05911154e-02,  2.48379684e-01,\n",
      "        -1.86769485e-02, -3.81761453e-01, -3.88162504e-01,\n",
      "        -6.41696781e-01, -8.04011948e-69, -1.31288203e-01,\n",
      "        -2.31458568e-01,  2.82041544e-01,  2.06700154e-82,\n",
      "         1.29811411e-02, -4.43947466e-02, -2.16833494e-01,\n",
      "         1.36073266e-01, -2.26141376e-01, -1.78550016e-58,\n",
      "        -1.30363943e-02,  4.16498661e-01,  9.62743973e-52,\n",
      "        -3.99725479e-02, -4.54346941e-02,  2.00941083e-01,\n",
      "         2.59456154e-01],\n",
      "       [-2.11632409e-03,  1.76097415e-01, -1.19270073e-01,\n",
      "        -3.69694874e-03, -2.20223615e-02,  1.72206208e-40,\n",
      "         2.82522647e-02,  4.26877846e-03,  3.72219346e-01,\n",
      "        -2.31861415e-46,  1.54431823e-01, -2.90205178e-01,\n",
      "        -1.61500407e-01, -1.60497058e-01,  4.17856321e-67,\n",
      "         2.63280371e-01, -7.05024305e-68, -7.01245714e-57,\n",
      "         2.69314688e-01,  9.47594181e-02,  9.54165799e-58,\n",
      "        -2.31541161e-01, -1.86131740e-01,  9.47478172e-55,\n",
      "         1.27588872e-58,  1.55463867e-71, -1.89180707e-01,\n",
      "        -3.30832170e-01,  1.96881106e-01, -1.98391367e-01,\n",
      "        -7.48548802e-50, -2.89995804e-01,  3.04994441e-01,\n",
      "        -2.84592849e-01, -3.48179373e-01, -1.58080651e-01,\n",
      "         1.77768279e-01, -2.40853973e-02, -1.64650435e-01,\n",
      "        -2.72087318e-01,  3.29469997e-01, -2.35825829e-01,\n",
      "        -2.92306492e-01,  3.80998642e-43,  3.70451525e-79,\n",
      "         1.89641450e-01, -2.60795933e-01,  2.12997317e-01,\n",
      "         1.92409377e-01, -1.39232638e-01, -2.29491037e-01,\n",
      "         2.17072398e-01,  7.50070157e-65, -5.72584778e-03,\n",
      "        -1.09517155e-02,  2.94656831e-01,  1.05764168e-01,\n",
      "         8.11949628e-02, -2.66514846e-01,  6.94662502e-02,\n",
      "         2.89763588e-60,  2.99711409e-01,  3.67394398e-01,\n",
      "         3.38347887e-01,  1.59663577e-76, -1.11159318e-01,\n",
      "         1.05974793e-39, -1.01427308e-02, -5.44480904e-01,\n",
      "        -5.11500382e-01,  1.60909747e-51,  1.94937095e-01,\n",
      "        -2.20360008e-83, -4.37425153e-01, -2.97027371e-01,\n",
      "        -2.60038641e-01,  5.37120206e-02,  1.83876096e-01,\n",
      "         5.89844689e-02, -3.80269964e-01, -1.83360932e-01,\n",
      "        -2.06881629e-01, -2.05964827e-69,  7.94035902e-04,\n",
      "        -3.00869801e-01,  3.21253004e-01, -7.35544074e-75,\n",
      "        -1.09217972e-01,  4.32422543e-02, -8.10642857e-02,\n",
      "         1.88210425e-01, -7.83254509e-02, -5.85080300e-46,\n",
      "         3.80249390e-01,  3.63956418e-01, -1.25981289e-49,\n",
      "         2.91894336e-01,  3.34270233e-01,  2.77918215e-01,\n",
      "        -9.80089163e-02],\n",
      "       [ 5.00592974e-01, -2.05055954e-01, -1.67091923e-01,\n",
      "         4.39634079e-01,  7.00888989e-02,  1.42879669e-69,\n",
      "        -1.65798734e-01,  2.16432613e-01, -4.79553921e-01,\n",
      "         1.48593649e-68, -1.00957765e+00,  5.23532875e-01,\n",
      "         4.88374214e-01,  4.90900950e-01,  6.66464457e-54,\n",
      "        -5.66174895e-01,  2.26835509e-68, -3.36857625e-55,\n",
      "        -1.41145316e-01,  1.36287740e-01,  2.18831457e-75,\n",
      "        -2.40598096e-01,  5.63333360e-01, -8.86581647e-84,\n",
      "         3.67964906e-78, -1.05309216e-74,  4.78144582e-01,\n",
      "        -1.79651073e-01, -2.77623975e-01,  5.28557452e-01,\n",
      "         8.59302928e-69,  6.54720835e-01, -5.99095326e-01,\n",
      "         3.37452626e-01,  5.97004474e-01,  4.14871535e-01,\n",
      "        -1.36307101e-01,  3.47663610e-01,  6.63326960e-01,\n",
      "         3.44645825e-01, -2.04541832e-01,  5.25642714e-01,\n",
      "        -5.07315981e-03, -3.84102901e-70,  3.25046891e-64,\n",
      "        -1.62363784e-01,  3.99772008e-01, -2.12842480e-01,\n",
      "        -2.79122316e-01,  1.20485934e-01,  6.81829695e-01,\n",
      "        -2.83717523e-01,  3.05587909e-44,  5.16583267e-01,\n",
      "        -1.35515537e+00, -4.45383149e-01, -1.97762619e-01,\n",
      "         5.93825461e-01, -6.59328662e-03,  4.85924411e-01,\n",
      "        -4.26119012e-74, -3.55535090e-01, -2.53256355e-01,\n",
      "        -2.34458120e-01,  5.03110631e-75, -1.30601318e-01,\n",
      "        -5.57247236e-81, -1.61831914e-03, -6.19657153e-02,\n",
      "         3.59022750e-01, -1.17976979e-77, -1.89789539e-01,\n",
      "        -2.95389802e-75, -2.44657855e-01,  4.20701299e-01,\n",
      "         3.37098514e-01,  3.91108872e-01, -2.46070930e-01,\n",
      "         1.60895921e-01,  4.48154242e-01,  5.34782194e-01,\n",
      "         4.23346809e-01, -8.85886466e-81,  4.25982565e-01,\n",
      "         6.45542345e-01, -4.10188197e-01, -3.43964794e-80,\n",
      "         5.16355252e-01, -3.20796379e-02,  5.16113017e-01,\n",
      "        -1.15295275e-01,  3.16649656e-01, -3.93106188e-45,\n",
      "        -1.58895021e-01, -3.15640953e-01, -4.39274703e-57,\n",
      "        -1.28997844e-01, -4.70820195e-01, -3.24716207e-01,\n",
      "        -6.76968338e-01],\n",
      "       [ 1.99655893e-01,  9.38114635e-03, -2.31186087e-01,\n",
      "         1.89224221e-01,  1.38484355e-01,  4.25439686e-65,\n",
      "         1.69100639e-01,  2.36304824e-01,  8.81102678e-02,\n",
      "        -1.09111654e-61, -2.29375115e-01,  1.28730966e-01,\n",
      "         4.84483863e-03, -9.96621025e-02, -5.70122908e-52,\n",
      "         1.74083509e-01, -6.63809766e-49, -4.04685853e-72,\n",
      "         1.09970796e-01, -6.62247969e-02,  4.41162453e-54,\n",
      "         2.95875279e-02, -2.30237745e-01, -3.66315893e-48,\n",
      "        -1.21269681e-61,  5.35600513e-55,  7.91039934e-02,\n",
      "        -1.06116240e-01,  6.55146777e-02,  1.23789567e-01,\n",
      "         1.16554237e-46,  1.36486371e-01,  1.89120636e-01,\n",
      "         2.91213089e-01,  6.00811377e-02, -2.61080040e-03,\n",
      "         4.27427360e-02,  1.81633259e-01, -8.97994205e-02,\n",
      "         3.10449174e-02,  1.26227359e-02,  1.87271626e-01,\n",
      "        -2.78550967e-01,  4.77800468e-65,  1.82825904e-40,\n",
      "        -1.11083390e-01, -5.00545219e-02,  1.31037697e-01,\n",
      "         1.48024167e-01, -2.56091998e-02,  1.14443198e-01,\n",
      "        -4.21983872e-04,  3.27543902e-75, -6.97581318e-02,\n",
      "        -1.97269361e-01, -1.95241561e-01, -2.26535292e-01,\n",
      "         1.86761694e-01,  7.67442915e-02, -1.59510085e-01,\n",
      "        -2.21656356e-56, -4.03915766e-02,  1.53131386e-01,\n",
      "         2.70455590e-02, -1.00641180e-69,  1.03995624e-02,\n",
      "         1.70175692e-43, -8.72106831e-07, -5.19244713e-01,\n",
      "        -2.44077079e-01,  4.23922696e-78,  3.00787426e-02,\n",
      "         5.25718474e-68, -2.68691210e-01,  3.06725255e-02,\n",
      "         2.05882487e-01,  2.33139976e-01, -1.26149402e-02,\n",
      "        -1.63058342e-01, -3.49830240e-01,  3.41193474e-01,\n",
      "         1.41739973e-02,  1.67587196e-76,  2.37925080e-01,\n",
      "        -5.28670214e-02, -1.00850467e-01, -1.16399571e-70,\n",
      "         4.06054618e-02,  1.63823705e-01,  2.79645574e-01,\n",
      "        -1.74088712e-01, -1.04749079e-01, -1.10055470e-79,\n",
      "        -6.26497611e-03,  3.11129540e-02, -1.07519972e-75,\n",
      "         2.90167529e-02,  1.90683235e-01, -3.03763492e-01,\n",
      "        -4.05049657e-02],\n",
      "       [-3.94280137e-01,  3.52550931e-01, -2.61801277e-01,\n",
      "        -6.03557385e-01, -1.68224371e-01, -4.23425162e-58,\n",
      "         5.36811594e-01, -1.87612020e-01,  2.71812717e-01,\n",
      "         3.78769285e-64,  3.58163682e-01, -4.89685317e-01,\n",
      "        -4.81930804e-01, -7.58459157e-01,  2.24626069e-75,\n",
      "         4.06807870e-01, -2.45825817e-59, -5.90267264e-55,\n",
      "         4.95753079e-01, -1.39635808e-01, -3.63654945e-79,\n",
      "        -8.64664708e-02, -6.86261501e-01,  4.49086124e-80,\n",
      "        -1.70621141e-70, -2.01521621e-53, -4.63106643e-01,\n",
      "         9.50318561e-02,  4.06809219e-01, -5.44128490e-01,\n",
      "         1.73389287e-61, -3.70069902e-01,  2.85852374e-01,\n",
      "        -3.87070335e-01, -3.27173889e-01, -6.22591695e-01,\n",
      "        -3.14585843e-02, -2.00427301e-01, -5.42797698e-01,\n",
      "        -3.84550865e-01,  5.13253543e-01, -6.66650882e-01,\n",
      "         5.49432866e-02, -1.23815554e-49,  1.46442343e-76,\n",
      "         4.27944483e-01, -3.30892649e-01,  1.50021204e-01,\n",
      "         3.91223690e-01,  2.41544058e-02, -2.52260428e-01,\n",
      "         5.27183285e-01, -1.03172434e-62, -6.37090489e-01,\n",
      "         8.13632811e-01,  5.74596912e-01,  1.78594495e-01,\n",
      "        -1.49038590e-01, -1.23173573e-01, -5.31489905e-01,\n",
      "         5.73185780e-67,  2.97369747e-01,  3.93982146e-01,\n",
      "         5.51850713e-01,  2.32030764e-40, -4.93423258e-02,\n",
      "         1.12589807e-77,  3.53926136e-06, -4.74950105e-01,\n",
      "        -5.27875108e-01, -3.94536740e-50, -1.83918345e-01,\n",
      "         2.44672946e-38, -2.00052473e-01, -6.09955305e-01,\n",
      "        -2.65761439e-01, -6.22161906e-01,  4.68011098e-01,\n",
      "        -5.29255817e-01, -6.89398711e-01, -4.72225294e-01,\n",
      "        -6.43816374e-01,  2.34497440e-78, -4.65534759e-01,\n",
      "        -4.07691167e-01,  4.53657548e-01,  5.82996862e-58,\n",
      "        -6.12600631e-01, -1.15711374e-01, -1.83944726e-01,\n",
      "         5.51199673e-01, -6.57948283e-01,  1.45802484e-61,\n",
      "         5.01792243e-01,  6.66461970e-01, -4.07145484e-72,\n",
      "         5.80904095e-01,  2.73330963e-01,  2.06885077e-01,\n",
      "         5.60569115e-01]]), array([[-2.89543089e-01],\n",
      "       [ 3.73435629e-01],\n",
      "       [ 1.16392200e-01],\n",
      "       [-3.43000203e-01],\n",
      "       [-8.87363014e-02],\n",
      "       [ 5.04330003e-37],\n",
      "       [ 3.39814224e-01],\n",
      "       [-1.92483741e-01],\n",
      "       [ 4.86563659e-01],\n",
      "       [ 7.63024515e-58],\n",
      "       [ 1.18651943e+00],\n",
      "       [-6.59382940e-01],\n",
      "       [-7.49378314e-01],\n",
      "       [-7.94204771e-01],\n",
      "       [ 4.22466860e-62],\n",
      "       [ 5.08563854e-01],\n",
      "       [-8.07676415e-60],\n",
      "       [ 1.90172330e-60],\n",
      "       [ 3.45015331e-01],\n",
      "       [-9.24375465e-02],\n",
      "       [-1.73505657e-81],\n",
      "       [ 5.56284365e-03],\n",
      "       [-9.36254862e-01],\n",
      "       [-1.23198625e-53],\n",
      "       [ 3.10323401e-83],\n",
      "       [-9.85877905e-49],\n",
      "       [-6.42645137e-01],\n",
      "       [ 6.47058162e-02],\n",
      "       [ 2.67943062e-01],\n",
      "       [-4.81281274e-01],\n",
      "       [ 9.67210277e-63],\n",
      "       [-1.01263067e+00],\n",
      "       [ 4.69810588e-01],\n",
      "       [-5.97249154e-01],\n",
      "       [-6.16365126e-01],\n",
      "       [-8.32552341e-01],\n",
      "       [-1.29046465e-01],\n",
      "       [-3.42672792e-01],\n",
      "       [-4.28502950e-01],\n",
      "       [-5.98318508e-01],\n",
      "       [ 4.60178603e-01],\n",
      "       [-9.04263438e-01],\n",
      "       [ 1.45784185e-01],\n",
      "       [-8.69146930e-45],\n",
      "       [-1.79958386e-75],\n",
      "       [ 3.32725270e-01],\n",
      "       [-5.10581804e-01],\n",
      "       [ 1.93288766e-01],\n",
      "       [ 4.64175266e-01],\n",
      "       [ 2.07980799e-01],\n",
      "       [-8.94374431e-01],\n",
      "       [ 4.40742621e-01],\n",
      "       [-1.03761748e-83],\n",
      "       [-5.82888644e-01],\n",
      "       [ 2.04371755e+00],\n",
      "       [ 5.84418281e-01],\n",
      "       [ 7.47284528e-02],\n",
      "       [-5.34430370e-01],\n",
      "       [ 1.73584564e-01],\n",
      "       [-4.46198620e-01],\n",
      "       [ 3.96533807e-53],\n",
      "       [ 4.56788990e-01],\n",
      "       [ 1.85822955e-01],\n",
      "       [ 4.31825350e-01],\n",
      "       [-4.01017459e-64],\n",
      "       [ 6.56743637e-03],\n",
      "       [ 3.61575408e-37],\n",
      "       [ 9.53792624e-03],\n",
      "       [-9.76295193e-01],\n",
      "       [-1.28016285e+00],\n",
      "       [ 2.88116139e-81],\n",
      "       [-1.21638595e-01],\n",
      "       [ 1.47571553e-76],\n",
      "       [-5.24887109e-01],\n",
      "       [-4.03864642e-01],\n",
      "       [-5.40160232e-01],\n",
      "       [-3.62899892e-01],\n",
      "       [ 1.27191540e-01],\n",
      "       [-3.63479659e-01],\n",
      "       [-1.01252731e+00],\n",
      "       [-1.10829206e+00],\n",
      "       [-6.43162813e-01],\n",
      "       [-4.15719397e-45],\n",
      "       [-3.53607982e-01],\n",
      "       [-5.40350083e-01],\n",
      "       [ 5.53527364e-01],\n",
      "       [-2.12131915e-79],\n",
      "       [-5.54358795e-01],\n",
      "       [-6.61183648e-02],\n",
      "       [-5.86461697e-01],\n",
      "       [ 3.36579842e-01],\n",
      "       [-1.17832526e+00],\n",
      "       [-1.97256699e-68],\n",
      "       [ 2.90182139e-01],\n",
      "       [ 3.34224958e-01],\n",
      "       [ 8.50750076e-41],\n",
      "       [ 2.00064951e-01],\n",
      "       [ 3.80262336e-01],\n",
      "       [ 2.04579178e-01],\n",
      "       [ 9.58897853e-01]])]\n"
     ]
    }
   ],
   "source": [
    "def convert_class(raw, num_class=2): #convert classes to binary or multinomial\n",
    "    raw = int(raw)\n",
    "    if num_class == 2:\n",
    "        if raw<=10: return 0\n",
    "        else: return 1\n",
    "    elif num_class == 3:\n",
    "        if raw <= 8:\n",
    "            return 0\n",
    "        elif 9<=raw<=10:\n",
    "            return 1\n",
    "        elif 11<=raw:\n",
    "            return 2\n",
    "    elif num_class == 29:\n",
    "        return raw\n",
    "\n",
    "def load_abalone(addsex=False, num_class=2):\n",
    "    X, y = [], []\n",
    "    with open('abalone.data', 'r') as fin:\n",
    "        for line in fin:\n",
    "            atts = line[:-1].split(\",\")\n",
    "            if not addsex:\n",
    "                X.append(atts[1:-1])\n",
    "            else:\n",
    "                sex = atts[0]\n",
    "                if sex == \"M\": sex = 0\n",
    "                elif sex==\"I\": sex = 1\n",
    "                elif sex==\"F\": sex = 2\n",
    "                else: sex = 3\n",
    "                \n",
    "                X.append([sex] + atts[1:-1])\n",
    "            y.append(convert_class(atts[-1], num_class))\n",
    "    X = np.array(X, dtype=float)\n",
    "    return X, y\n",
    "\n",
    "X, y = load_abalone(addsex=False, num_class=2)\n",
    "print('X:', X.shape, 'y:', set(y))\n",
    "\n",
    "clf = MLPClassifier(max_iter=2000)\n",
    "clf.fit(X,y)\n",
    "print(clf.coefs_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.(b) \n",
    "(Harder) Change the size and/or number of hidden layers. How are the resulting weights affected? Can you discern any relationship between the weights for layers of varying sizes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.07747804, -0.05470933, -0.22873315,  0.14042917,  0.27367439,\n",
      "        -0.16751675, -0.38023649,  0.62046604, -0.14810798, -0.25364371],\n",
      "       [-0.37936501,  0.50563958, -0.23247282, -0.38008997, -0.15552607,\n",
      "         0.43910963, -0.0588767 ,  0.335598  ,  0.63546494, -0.04346653],\n",
      "       [-0.05153807, -0.25125844,  0.49841425, -0.93351084,  0.24654007,\n",
      "         0.38504697, -0.29706621, -0.57498998, -0.58760191,  0.05332798],\n",
      "       [-0.19079326,  0.35819438,  0.70520953,  0.15816268,  0.70457358,\n",
      "         0.64342869, -0.55295313, -0.30254355, -0.10952335,  0.32856662],\n",
      "       [ 0.41309896, -0.34167007,  1.14939554,  1.05403077, -0.5182208 ,\n",
      "        -0.78080423, -0.12755564,  0.6335394 ,  0.72025471, -0.35737822],\n",
      "       [ 0.34117412,  0.50256056, -0.13763266, -0.11700591, -0.06680289,\n",
      "        -0.5814316 , -0.36058434,  0.36088966,  0.03337964,  0.35324359],\n",
      "       [-0.640471  ,  1.08753606, -0.67645879, -0.17344297,  0.02323189,\n",
      "         0.71663396,  0.52716417, -0.72737425, -0.1222358 , -0.43085243]]), array([[-5.52695012e-001,  1.66143431e-001, -2.81234763e-001,\n",
      "        -2.79546718e-001,  5.87380531e-001,  5.06576492e-120,\n",
      "         1.25596400e+000, -1.72037096e-002, -1.68766269e-001,\n",
      "        -5.08919904e-001],\n",
      "       [ 3.69827710e-001,  2.23610161e-001, -3.41316023e-001,\n",
      "         7.10113955e-001,  4.39745380e-001, -1.23503194e-085,\n",
      "        -5.80579515e-001, -4.76901622e-001, -5.50688302e-001,\n",
      "        -3.86087013e-001],\n",
      "       [ 2.08525712e-001, -6.75619480e-001, -3.40564500e-001,\n",
      "         4.98526518e-001, -5.79340303e-001, -2.98045506e-099,\n",
      "        -1.56361327e-001,  5.57966045e-001,  6.10111151e-001,\n",
      "         3.80602710e-001],\n",
      "       [-1.01429648e-001, -9.19147818e-001,  1.40024695e-001,\n",
      "        -2.42196523e-001,  5.95377623e-001, -9.95575408e-125,\n",
      "         3.04643195e-001, -6.04750215e-001,  6.25780784e-001,\n",
      "        -4.55670431e-001],\n",
      "       [ 4.63025636e-001,  6.22700707e-002,  1.49435164e-001,\n",
      "         6.97664471e-001, -3.42249421e-001, -2.47580743e-095,\n",
      "        -3.20346410e-001,  3.51623483e-001, -3.74506209e-001,\n",
      "        -5.56931103e-001],\n",
      "       [ 5.35484630e-001,  6.25772437e-001,  3.89199809e-002,\n",
      "         7.92473909e-001, -3.12165358e-001, -9.22884394e-096,\n",
      "        -4.88583578e-001,  4.23086781e-001, -1.88471947e-001,\n",
      "        -3.03821776e-001],\n",
      "       [ 1.18021693e-001, -1.68305105e-001,  4.89281106e-001,\n",
      "        -3.34232904e-001,  7.50927980e-001, -4.42266938e-117,\n",
      "         4.25303898e-001,  3.03183276e-002,  7.95595994e-001,\n",
      "        -1.90749231e-001],\n",
      "       [-4.16288575e-001, -3.59449569e-001,  4.56557784e-001,\n",
      "        -8.43844402e-001,  4.72800353e-001, -7.32222642e-040,\n",
      "         6.50431501e-001, -7.64481030e-001,  4.00513665e-001,\n",
      "        -5.05504070e-001],\n",
      "       [ 1.81395441e-001, -1.78421465e-002,  4.37359786e-001,\n",
      "         1.47500074e-001,  3.04689264e-002,  8.14045581e-115,\n",
      "         5.91153896e-001, -2.46459278e-001,  1.69747421e-001,\n",
      "        -5.25843672e-002],\n",
      "       [-1.10852314e-009,  1.33629187e-003,  2.26637068e-089,\n",
      "         4.77642806e-005,  3.31335929e-003, -7.57660331e-048,\n",
      "        -1.50494816e-094, -8.22321023e-038,  3.73265965e-002,\n",
      "         2.88049788e-044]]), array([[-1.27572541e-001, -3.06933440e-001,  7.38282328e-001,\n",
      "        -3.39472215e-001],\n",
      "       [-1.04262349e+000, -2.38003755e-001,  1.47817568e+000,\n",
      "        -1.83675696e+000],\n",
      "       [ 6.01598722e-001, -1.35429538e-001,  1.86371367e-001,\n",
      "         3.11699004e-001],\n",
      "       [-2.24541794e-001, -2.89206534e-001,  8.89452480e-001,\n",
      "        -5.30470508e-002],\n",
      "       [ 9.03443443e-001, -1.11134813e-003, -3.86250641e-001,\n",
      "         1.16766313e+000],\n",
      "       [ 2.08641993e-031,  4.56291397e-052,  3.29795744e-106,\n",
      "         1.80999458e-124],\n",
      "       [ 1.16044450e+000, -1.89048410e-003, -8.76473720e-001,\n",
      "         1.63488239e+000],\n",
      "       [ 1.15947541e+000, -4.23544552e-048, -7.92414193e-001,\n",
      "         1.94904016e+000],\n",
      "       [ 6.73740535e-001,  1.58750073e-001, -7.15709891e-001,\n",
      "         1.58744784e-001],\n",
      "       [-5.52022168e-001,  6.08537355e-002,  1.26308009e-002,\n",
      "         2.50557450e-001]]), array([[-1.39382561],\n",
      "       [ 0.20093328],\n",
      "       [ 0.58049082],\n",
      "       [-1.47563087]])]\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=[10, 10, 4], max_iter=2000)\n",
    "#this way we don't cheat read more on pipelines https://scikit-learn.org/stable/modules/compose.html\n",
    "clf.fit(X, y)\n",
    "print(clf.coefs_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4. \n",
    "There are a couple of different tune-able parameters for the MLPClassifier , mostly dealing with the weight optimisation â€” however, it is often worthwhile to tune the Regularisation parameter (Î±).\n",
    "### Exercise 4.(a) \n",
    "Try varying orders of Î± between 10 and 10 âˆ’5 for a Multilayer Perceptron built on the two-class `Abalone` data. How much variance in cross-validation accuracy do you observe?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0]\n",
      "alpha: 1e-07 mean_acc: 0.7866879637853479 standard_dev_acc: 0.011786261177182398\n",
      "alpha: 1e-06 mean_acc: 0.7859708334527118 standard_dev_acc: 0.014829799840827232\n",
      "alpha: 1e-05 mean_acc: 0.789322121307624 standard_dev_acc: 0.01272368051453238\n",
      "alpha: 0.0001 mean_acc: 0.7914766638970862 standard_dev_acc: 0.01631058225567131\n",
      "alpha: 0.001 mean_acc: 0.7862103544107957 standard_dev_acc: 0.012525224560086302\n",
      "alpha: 0.01 mean_acc: 0.7859716929776811 standard_dev_acc: 0.012914006996107273\n",
      "alpha: 0.1 mean_acc: 0.7854926510615133 standard_dev_acc: 0.012532362559726508\n",
      "alpha: 1.0 mean_acc: 0.7783067358106753 standard_dev_acc: 0.023521912445921667\n",
      "alpha: 10.0 mean_acc: 0.7407260120906513 standard_dev_acc: 0.03022452770631513\n"
     ]
    }
   ],
   "source": [
    "alphas = [np.power(10.0, i) for i in range(-7, 2)] # alpha is the learning rate\n",
    "print(alphas)\n",
    "\n",
    "for alpha in alphas:\n",
    "    clf = MLPClassifier(max_iter=2000, alpha=alpha)\n",
    "    pipeline = Pipeline([('transformer', scaler), ('estimator', clf)])\n",
    "    scores = cross_val_score(pipeline, X, y, cv=5)\n",
    "    print('alpha: {} mean_acc: {} standard_dev_acc: {}'.format(alpha, np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.(b) \n",
    "Read up on the `GridSearchCV` utility, to help you in tuning the performance of the *Multilayer Perceptron*. Split the data into a trainingâ€“andâ€“tuning partition, and a test partition. What is the value of the regularisation parameter that `GridSearchCV` comes up with? How does the test accuracy compare to the default (un-tuned) `MLPClassifier` ? \n",
    "\n",
    "*>>Please note that running this part can take some time. Be patient! ;)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP acc without tuning: 0.7739234449760766\n",
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   24.2s\n",
      "[Parallel(n_jobs=2)]: Done  54 out of  54 | elapsed:   26.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params {'alpha': 0.0001, 'hidden_layer_sizes': [10, 10]}\n",
      "acc with best params: 0.7727272727272727\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_devtest, y_train, y_devtest = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_dev, X_test, y_dev, y_test = train_test_split(X_devtest, y_devtest, test_size=0.5, random_state=42)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print('MLP acc without tuning:', clf.score(X_test, y_test))\n",
    "\n",
    "hidden_sizes = [[100], [10, 10]]\n",
    "#arguments of MLPClassifier and a list of values for them to search and find the best.\n",
    "param_grid = {'alpha': alphas, 'hidden_layer_sizes':hidden_sizes}\n",
    "\n",
    "\n",
    "gs = GridSearchCV(estimator=clf,\n",
    "                  param_grid=param_grid,\n",
    "                  scoring='accuracy',\n",
    "                  cv=3,\n",
    "                  n_jobs=2, # \n",
    "                  verbose=1) #\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "best_params = gs.best_params_\n",
    "print('best_params', best_params)\n",
    "clf = MLPClassifier(max_iter=2000, **best_params) # ** => double power, to the power of the best parameter => kwargs\n",
    "clf.fit(X_train, y_train)\n",
    "print('acc with best params:', clf.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
